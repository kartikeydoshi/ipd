{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOkzWPQZ2o95"
      },
      "source": [
        "## Loading data and preliminary analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies \n",
        "\n",
        "%pip install -r '../requirements.txt'\n",
        "\n",
        "import nltk \n",
        "\n",
        "# nltk.download('punkt') \n",
        "# nltk.download('averaged_perceptron_tagger') \n",
        "\n",
        "# Set paths \n",
        "\n",
        "path_to_csv = '../Dataset/mentalhealth.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOYdKHMxxo-G"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.set_option('mode.chained_assignment', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWkNB_E2xo7N"
      },
      "outputs": [],
      "source": [
        "data=pd.read_csv(path_to_csv, nrows=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "Lv-3MPz-HGUA",
        "outputId": "eaeac595-e920-4273-e24e-d9814042a74f"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkrA850QxovH"
      },
      "outputs": [],
      "source": [
        "# data preprocessing \n",
        "\n",
        "for i in range(data.shape[0]):\n",
        "  data['Answers'][i]=re.sub(r'\\n', ' ',data['Answers'][i])\n",
        "  data['Answers'][i]=re.sub('\\(', '',data['Answers'][i]) \n",
        "  data['Answers'][i]=re.sub(r'\\)', '',data['Answers'][i]) \n",
        "  data['Answers'][i]=re.sub(r',', '',data['Answers'][i]) \n",
        "  data['Answers'][i]=re.sub(r'-', '',data['Answers'][i])\n",
        "  data['Answers'][i]=re.sub(r'/', '',data['Answers'][i])  \n",
        "  data['Answers'][i]=re.sub(r'/', '',data['Answers'][i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0hDQnIg5NmU"
      },
      "outputs": [],
      "source": [
        "pairs=[]\n",
        "\n",
        "for i in range(data.shape[0]):\n",
        "  pairs.append(((data['Questions'][i]),data['Answers'][i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e6HSAiT5sGJ",
        "outputId": "20556148-c5da-48ec-d9ab-ba292eb7e700"
      },
      "outputs": [],
      "source": [
        "pairs                                     # questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFIMImgr25tw"
      },
      "source": [
        "## Data preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPdw-Uwt60QW"
      },
      "outputs": [],
      "source": [
        "input_docs = []\n",
        "target_docs = []\n",
        "input_tokens = set()\n",
        "target_tokens = set()\n",
        "\n",
        "for line in pairs:\n",
        "\n",
        "  input_doc, target_doc = line[0], line[1]\n",
        "\n",
        "  # Appending each input sentence to input_docs\n",
        "  input_docs.append(input_doc)\n",
        "\n",
        "  # Splitting words from punctuation  \n",
        "  target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n",
        "\n",
        "  # Redefine target_doc below and append it to target_docs\n",
        "  target_doc = '<START> ' + target_doc + ' <END>'\n",
        "\n",
        "  target_docs.append(target_doc)\n",
        "\n",
        "  for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n",
        "    if token not in input_tokens:\n",
        "      input_tokens.add(token)\n",
        "  for token in target_doc.split():\n",
        "    if token not in target_tokens:\n",
        "      target_tokens.add(token)\n",
        "\n",
        "input_tokens = sorted(list(input_tokens))  # contains all words of input_docs\n",
        "target_tokens = sorted(list(target_tokens))\n",
        "num_encoder_tokens = len(input_tokens)\n",
        "num_decoder_tokens = len(target_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BgbOOFBDXRQ",
        "outputId": "60bbba79-0099-4092-a15b-67b5acbed793"
      },
      "outputs": [],
      "source": [
        "input_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gzh0qjP60LN",
        "outputId": "ad09f47c-566d-4024-e0e7-b9aca3a029ca"
      },
      "outputs": [],
      "source": [
        "target_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NetKOKUa6ucB"
      },
      "outputs": [],
      "source": [
        "input_features_dict = dict([(token, i) for i, token in enumerate(input_tokens)])\n",
        "target_features_dict = dict([(token, i) for i, token in enumerate(target_tokens)])\n",
        "\n",
        "reverse_input_features_dict = dict((i, token) for token, i in input_features_dict.items())\n",
        "reverse_target_features_dict = dict((i, token) for token, i in target_features_dict.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HjeF1rV5r1o",
        "outputId": "f485be5a-5965-4907-938f-3bc0fd1356c4"
      },
      "outputs": [],
      "source": [
        "input_features_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1xvXlXR3Rjo"
      },
      "source": [
        "## Encoder - Decoder model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4SCSarcDJm3"
      },
      "outputs": [],
      "source": [
        "max_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)) for input_doc in input_docs])\n",
        "max_decoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc)) for target_doc in target_docs])\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_docs), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n",
        "    for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n",
        "        #Assign 1. for the current line, timestep, & word in encoder_input_data\n",
        "        encoder_input_data[line, timestep, input_features_dict[token]] = 1.\n",
        "    \n",
        "    for timestep, token in enumerate(target_doc.split()):\n",
        "        decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n",
        "        if timestep > 0:\n",
        "            decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_TCl5B2c9Vq",
        "outputId": "029afdc1-421e-497d-a92b-fe361d1ab15c"
      },
      "outputs": [],
      "source": [
        "encoder_input_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLXrUXkxOehp",
        "outputId": "738aba50-0667-45dd-8f4d-c3632857f228"
      },
      "outputs": [],
      "source": [
        "decoder_target_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6M74GLqQ32ET"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADU7bfIXOefe"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "from keras.models import Model  \n",
        "dimensionality = 256 # Dimensionality \n",
        "batch_size = 10   # The batch size and number of epochs\n",
        "epochs = 500 \n",
        "\n",
        "#Encoder\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder_lstm = LSTM(dimensionality, return_state=True)\n",
        "encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [state_hidden, state_cell]\n",
        "\n",
        "#Decoder\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "decoder_lstm = LSTM(dimensionality, return_sequences=True, return_state=True)\n",
        "decoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tA1W1_-HOecW"
      },
      "outputs": [],
      "source": [
        "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs) # Compiling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9EEk4_KLLy2",
        "outputId": "e7348b85-4be2-4e3d-dfe1-791b762214c0"
      },
      "outputs": [],
      "source": [
        "training_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "n9HeMTwusJ-Y",
        "outputId": "af3f2187-529f-43a7-abf3-57ca78dd3271"
      },
      "outputs": [],
      "source": [
        "plot_model(training_model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)   # plot model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzwmitzgJ4zj",
        "outputId": "94589bfb-ee56-4b4c-8ba7-f61628c3cb24"
      },
      "outputs": [],
      "source": [
        "training_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode='temporal')#Training\n",
        "history1=training_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = batch_size, epochs = epochs, validation_split = 0.2)\n",
        "training_model.save('training_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "uZxR-20DvbVK",
        "outputId": "e564486f-1105-48c1-d2c0-b2c213d8b0c6"
      },
      "outputs": [],
      "source": [
        "acc = history1.history['accuracy']\n",
        "val_acc = history1.history['val_accuracy']\n",
        "loss=history1.history['loss']\n",
        "val_loss=history1.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVjdY1_syVNo"
      },
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-BO7-WLPW9i"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "training_model = load_model('training_model.h5')\n",
        "encoder_inputs = training_model.input[0]\n",
        "encoder_outputs, state_h_enc, state_c_enc = training_model.layers[2].output\n",
        "encoder_states = [state_h_enc, state_c_enc]\n",
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qYOVJPCPW5-"
      },
      "outputs": [],
      "source": [
        "latent_dim = 256\n",
        "decoder_state_input_hidden = Input(shape=(latent_dim,))\n",
        "decoder_state_input_cell = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7rEX_--PW3a"
      },
      "outputs": [],
      "source": [
        "decoder_outputs, state_hidden, state_cell = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_hidden, state_cell]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOYDxa10OeZ6"
      },
      "outputs": [],
      "source": [
        "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGLxFzOXOeW3"
      },
      "outputs": [],
      "source": [
        "training_model = load_model('training_model.h5')\n",
        "encoder_inputs = training_model.input[0]\n",
        "encoder_outputs, state_h_enc, state_c_enc = training_model.layers[2].output\n",
        "encoder_states = [state_h_enc, state_c_enc]\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "latent_dim = 256\n",
        "decoder_state_input_hidden = Input(shape=(latent_dim,))\n",
        "decoder_state_input_cell = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]\n",
        "decoder_outputs, state_hidden, state_cell = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_hidden, state_cell]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
        "\n",
        "def decode_response(test_input):\n",
        "    #Getting the output states to pass into the decoder\n",
        "    states_value = encoder_model.predict(test_input)\n",
        "    \n",
        "    #Generating empty target sequence of length 1\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    \n",
        "    #Setting the first token of target sequence with the start token\n",
        "    target_seq[0, 0, target_features_dict['<START>']] = 1.\n",
        "    \n",
        "    #A variable to store our response word by word\n",
        "    decoded_sentence = ''\n",
        "    \n",
        "    stop_condition = False\n",
        "    while not stop_condition:\n",
        "          #Predicting output tokens with probabilities and states\n",
        "          output_tokens, hidden_state, cell_state = decoder_model.predict([target_seq] + states_value)\n",
        "          \n",
        "          #Choosing the one with highest probability\n",
        "          sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "          sampled_token = reverse_target_features_dict[sampled_token_index]\n",
        "          decoded_sentence += \" \" + sampled_token\n",
        "          \n",
        "          #Stop if hit max length or found the stop token\n",
        "          if (sampled_token == '<END>' or len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "          \n",
        "          #Update the target sequence\n",
        "          target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "          target_seq[0, 0, sampled_token_index] = 1.\n",
        "          \n",
        "          #Update states\n",
        "          states_value = [hidden_state, cell_state]\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_haf70rOeUf"
      },
      "outputs": [],
      "source": [
        "class ChatBot:\n",
        "  negative_responses = (\"no\", \"nope\", \"nah\", \"naw\", \"not a chance\", \"sorry\")\n",
        "  exit_commands = (\"quit\", \"pause\", \"exit\", \"goodbye\", \"bye\", \"later\", \"stop\")\n",
        "  \n",
        "  #Method to start the conversation\n",
        "  def start_chat(self):\n",
        "    user_response = input(\"Hi, I'm a chatbot trained on random dialogs. AMA!\\n\")\n",
        "    \n",
        "    if user_response in self.negative_responses:\n",
        "      print(\"Ok, have a great day!\")\n",
        "      return\n",
        "    self.chat(user_response)\n",
        "  \n",
        "  #Method to handle the conversation\n",
        "  def chat(self, reply):\n",
        "    while not self.make_exit(reply):\n",
        "      reply = input(self.generate_response(reply)+\"\\n\")\n",
        "    \n",
        "  #Method to convert user input into a matrix\n",
        "  def string_to_matrix(self, user_input):\n",
        "    tokens = re.findall(r\"[\\w']+|[^\\s\\w]\", user_input)\n",
        "    user_input_matrix = np.zeros(\n",
        "      (1, max_encoder_seq_length, num_encoder_tokens),\n",
        "      dtype='float32')\n",
        "    for timestep, token in enumerate(tokens):\n",
        "      if token in input_features_dict:\n",
        "        user_input_matrix[0, timestep, input_features_dict[token]] = 1.\n",
        "    return user_input_matrix\n",
        "  \n",
        "  #Method that will create a response using seq2seq model we built\n",
        "  def generate_response(self, user_input):\n",
        "    input_matrix = self.string_to_matrix(user_input)\n",
        "    chatbot_response = decode_response(input_matrix)\n",
        "    #Remove <START> and <END> tokens from chatbot_response\n",
        "    chatbot_response = chatbot_response.replace(\"<START>\",'')\n",
        "    chatbot_response = chatbot_response.replace(\"<END>\",'')\n",
        "    return chatbot_response\n",
        "  \n",
        "  #Method to check for exit commands\n",
        "  def make_exit(self, reply):\n",
        "    for exit_command in self.exit_commands:\n",
        "      if exit_command in reply:\n",
        "        print(\"Ok, have a great day!\")\n",
        "        return True\n",
        "    return False\n",
        "  \n",
        "chatbot = ChatBot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex0L82Zh4nC1"
      },
      "source": [
        "## Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORcESPLnr2gS",
        "outputId": "802286d4-7228-4091-f91b-2c9f2f790b15"
      },
      "outputs": [],
      "source": [
        "chatbot.start_chat()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Generative based",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
